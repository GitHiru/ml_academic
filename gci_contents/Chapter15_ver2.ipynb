{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15 総合演習問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＜章トビラ＞\n",
    "\n",
    "いよいよ最後の章になりました。この章では、総合問題演習に取り組んでもらいます。今までに習ったデータサイエンスに関する色々な手法（データの読み込み、加工、機械学習のモデリング、検証など）が身に付いているかどうか確認するために、ぜひ取り組んでみてください。\n",
    "\n",
    "ゴール：問題解決に必要な手法を探し当て、適切に使用することができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **[15.1 総合演習問題を解くための準備](#15.1-総合演習問題を解くための準備)**\n",
    "<br><br>\n",
    "- **[15.2 総合演習問題（1）](#15.2-総合演習問題（1）)**\n",
    "<br><br>\n",
    "- **[15.3 総合演習問題（2）](#15.3-総合演習問題（2）)**\n",
    "<br><br>\n",
    "- **[15.4 総合演習問題（3）](#15.4-総合演習問題（3）)**\n",
    "<br><br>\n",
    "- **[15.5 総合演習問題（4）](#15.5-総合演習問題（4）)**\n",
    "<br><br>\n",
    "- **[15.6 総合演習問題（5）](#15.6-総合演習問題（5）)**\n",
    "<br><br>\n",
    "- **[15.7 総合演習問題（6）](#15.7-総合演習問題（6）)**\n",
    "<br><br>\n",
    "- **[15.8 参考：今後のデータ分析に向けて](#15.8-参考：今後のデータ分析に向けて)**\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.1 総合演習問題を解くための準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.3f'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以下は必要なライブラリのため、あらかじめ読み込んでおいてください。\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import scipy as sp\n",
    "from pandas import Series,DataFrame\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# 可視化ライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# 機械学習ライブラリ\n",
    "import sklearn\n",
    "\n",
    "# 小数第３位まで表示\n",
    "%precision 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.2 総合演習問題（1）\n",
    "キーワード：教師あり学習、画像認識、複数カテゴリーの分類、混同行列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learnの`sklearn.datasets`パッケージに入っている手書き数字のデータセットを下記のように読み込み、各数字（0〜9）を予測するモデルを構築しましょう。このデータは、手書きの数字で、0から9までの画像データです。以下の実装では、データを読み込み、サンプルとなる数字の画像データを表示しています。\n",
    " \n",
    "数字のラベル（目的変数）が`digits.target`で、そのデータの特徴量（説明変数）は`digits.data`です。ここで、このデータをテストデータと学習データに分けてモデルを構築し、混同行列の結果を表示させてください。その際、何度実行しても同じように分離されるように`train_test_split`のパラメータで`random_state=0`と設定してください。\n",
    "\n",
    "また、いくつかモデルを作成し、比較してみてください。どのモデルを使いますか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHsAAACNCAYAAAAn1Xb5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22366deaac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 分析対象データ\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "# 画像の表示\n",
    "plt.figure(figsize=(20,5))\n",
    "for label, img in zip(digits.target[:10], digits.images[:10]):\n",
    "    plt.subplot(1,10,label+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img,cmap=plt.cm.gray_r,interpolation='nearest')\n",
    "    plt.title('Number:{0}'.format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.3 総合演習問題（2）\n",
    "キーワード：教師あり学習、回帰、複数モデルの比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のデータを読み込み、アワビの年齢を予測するモデルを構築してみましょう。目的変数は、「`Rings`」になります。 英語ですが参考URL「B-26」に参考情報を挙げてあります。\n",
    "\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.4 総合演習問題（3）\n",
    "キーワード：教師あり学習、分類、マーケティング分析、検証、混同行列、正解率、適合率、再現率、F1スコア、ROC曲線、AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12章で扱った、以下の金融機関のデータ（bank-full.csv）を読み込んで、後の問いに答えてください。\n",
    "\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  数値データ（`age,balance,day,duration,campaign,pdays,previous`）における基本統計量（レコード数、最大値、最小値、標準偏差など）を算出してください。  \n",
    "2.  データの`\"job\",\"marital\",\"education\",\"default\",\"housing\",\"loan\"`のそれぞれについて、預金を申し込む人、申し込まない人の人数を算出してください。　　\n",
    "3.   `y`（預金を申し込む、申し込まない）を目的変数として、予測モデルを構築してください。モデルは複数（ロジスティック回帰、SVM、決定木、k-NN、ランダムフォレストなど）を試してください。ただし、テスト用にデータはあらかじめ抜いてください（その際、`train_test_split`のパラメータは`random_state=0`で設定してください）。     \n",
    "4.   テスト用のデータを使って、それぞれのモデルの検証をしましょう。各モデルのテストデータにおける正解率、適合率、再現率、F1スコア、混同行列を表示してください。どのモデルを使いますか。  \n",
    "5.   それぞれのモデルのROC曲線を描いて、AUCを算出し、比較できるようにしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.5 総合演習問題（4）\n",
    "キーワード：教師あり学習、教師なし学習、ハイブリッドアプローチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11章で扱ったload_breast_cancerを使って、さらに予測精度（正解率）を上げるモデルを作成してみましょう。同じく、テスト用にデータはあらかじめ抜いて検証してください。その際、`train_test_split`のパラメータが`random_state=0`に設定してください。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 前回の解答\n",
    "# 標準化のためのモジュール\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ロジスティック回帰\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, stratify = cancer.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 標準化\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: LogisticRegression 0.990610328638\n",
      "test: LogisticRegression 0.958041958042\n",
      "Confution matrix:\n",
      "[[50  3]\n",
      " [ 3 87]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = LogisticRegression()\n",
    "clf = model.fit(X_train_std,y_train)\n",
    "print(\"train:\",clf.__class__.__name__ ,clf.score(X_train_std,y_train))\n",
    "print(\"test:\",clf.__class__.__name__ , clf.score(X_test_std,y_test))\n",
    "\n",
    "pred_y = clf.predict(X_test_std)\n",
    "confusion_m = confusion_matrix(y_test,pred_y)\n",
    "\n",
    "print(\"Confution matrix:\\n{}\".format(confusion_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データを標準化して、単純にモデルを当てはめるとテストデータで正解率95.8％でした。この結果を上回る方法を考えてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.6 総合演習問題（5）\n",
    "キーワード：時系列データ、欠損データの補完、シフト、ヒストグラム、教師あり学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のように、2001年1月2日から2016年12月30日までの為替データ（ドル/円レートのJPYUSDとユーロ/ドルレートのUSDEUR）を読み込み、問いに答えてください。なお、DEXJPUSとDEXUSEUがそれぞれJPYUSDとUSDEURに想定しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 読み込んだデータには、祝日や休日等による欠損（NaN）があります。その補完処理をするために、直近の前の日におけるデータで補完してください。ただし年月のデータがない場合もありますので、その場合、今回は無視してください（改めて日付データを作成して、分析をすることも可能ですが、今回はこのアプローチはとりません。）。  \n",
    "2. 上記のデータで、各統計量の確認と時系列のグラフ化をしてください。  \n",
    "3. 当日と前日における差分をとり、それぞれの変化率（当日-前日）/前日のデータをヒストグラムで表示してください。　　  \n",
    "4. 将来の価格（例：次の日）を予測するモデルを構築してみましょう。具体的には、2016年11月を訓練データとして、当日の価格を目的変数として、前日、前々日、3日前の価格データを使ってモデル（線形回帰）を構築し、2016年12月をテストデータとして、検証してください。また、他の月や年で実施すると、どんな結果になりますか。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、以下を実行して、データをダウンロードしてください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pandas-datareader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下で、対象となる期間の為替データを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas_datareader.data as pdr\n",
    "\n",
    "start_date = \"2001-01-02\"\n",
    "end_date = \"2016-12-30\"\n",
    "\n",
    "fx_jpusdata = pdr.DataReader(\"DEXJPUS\",\"fred\",start_date,end_date)\n",
    "fx_useudata = pdr.DataReader(\"DEXUSEU\",\"fred\",start_date,end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.7 総合演習問題（6）\n",
    "キーワード：時系列データ、回帰分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の米国の旅客飛行機のフライトデータ」を取得し、読み込んで以下の問いに答えてください。ただし、今回は1980年代を分析対象とします。（PCのスペックがある方は、すべてのデータを対象にしてください。）\n",
    "\n",
    "http://stat-computing.org/dataexpo/2009/the-data.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. データを読み込んだ後は、年（Year）×月（Month）の平均の出発遅延時間（DepDelay）を算出してください。何かわかることはありますか。  \n",
    "2. 1で算出したデータについて、1月から12月までの結果を時系列の折れ線グラフにしてください。その時、年ごとに比較できるように、1つのグラフにまとめてください。1987年から1989年までのデータについて、それぞれの時系列グラフが並ぶイメージです。\n",
    "\n",
    "3. 各航空会社（UniqueCarrier）ごとの平均遅延時間を算出してください。また、出発地（Origin）、目的地（Dest）を軸にして、平均遅延時間を算出してください。  \n",
    "4. 遅延時間を予測するための予測モデルを構築します。目的変数をDepDelay、説明変数をArrDelay（実際の到着時間？）とDistance（飛行距離？）にして、モデルを構築しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**[ヒント]**\n",
    ">\n",
    ">データの取得は、以下のスクリプトを参考に、実装と実行をしてください。ただし、以下を実行する場合は別ファイルとして、「ファイル名.sh」の形式で保存し、そのファイルをここで実行する場合は、「bash ファイル名.sh」で実行します。もしくは、terminalに移動し、専用のディレクトリなどを作って、スクリプトを実行して、データを取得してください。他、Pythonから取得する方法もありますし、以前はzipを展開してデータを読み込んでいましたが、zipのまま加工できるプログラムも書けますので、ぜひ調べてやってみてください。**なお、データのダウンロードにとても時間がかかりますので、注意しましょう。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ヒント\n",
    "#参考シェルスクリプト：\n",
    "\n",
    "#!/bin/sh\n",
    "\n",
    "for year in {1987..1999} ; do  \n",
    "    echo ¥$year  \n",
    "    wget http://stat-computing.org/dataexpo/2009/${year}.csv.bz2  \n",
    "    bzip2 -d ${year}.csv.bz2  \n",
    "done  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なお、上記はLinuxやMacの環境の方のみで、Windowsの方は以下のようなスクリプトで圧縮ファイルをダウンロードして解凍してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "for year in range(1987,2000):    \n",
    "    url = 'http://stat-computing.org/dataexpo/2009/'\n",
    "    savename = str(year) + '.csv.bz2'\n",
    "    \n",
    "    #ダウンロード \n",
    "    urllib.request.urlretrieve(url + savename, savename)\n",
    "    print('{}年のファイルを保存しました'.format(year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.8 参考：今後のデータ分析に向けて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下は参考ですが、次のようなオープンデータを使って、データ分析に取り組んでみましょう。課題は明確になっていませんが、その課題を見つけることもデータ分析では大事です。\n",
    "\n",
    "1. どのデータを分析対象にしますか？また、どんなことを目的にデータを分析しますか？どんなことをゴールにしますか？    \n",
    "2. 分析対象となるデータに何か特徴や傾向はありますか？簡易集計してみましょう。そこからどんな仮設を立てますか？  \n",
    "3. 目的や仮説等が明確になったら、どんな風にアプローチしますか？実装して、検証してください。  \n",
    "4. 分析に明るくない人たち（中学校までの数学しかわからないと想定）に今回の分析結果を報告するとして、どのような報告書（グラフやインサイトなど含む）を作成しますか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なお、課題を特定していくことの重要性については、参考書籍「A-37」も参考になりますので、興味のある方は読んでみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### データソースサンプル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- UCI DATA\n",
    "\n",
    "http://archive.ics.uci.edu/ml/\n",
    "\n",
    "- Bay Area Bike Share\n",
    "\n",
    "http://www.bayareabikeshare.com/open-data\n",
    "　　\n",
    "- movielens\n",
    "\n",
    "http://grouplens.org/datasets/movielens/\n",
    "\n",
    "\n",
    "- MLDATA\n",
    "\n",
    "http://mldata.org/\n",
    "\n",
    "- Churn Data Set（provided by IBM）\n",
    "\n",
    "https://community.watsonanalytics.com/wp-content/uploads/2015/03/WA_Fn-UseC_-Telco-Customer-Churn.csv\n",
    "\n",
    "- Netflix Prize Data Set　　\n",
    "\n",
    "http://academictorrents.com/details/9b13183dc4d60676b773c9e2cd6de5e5542cee9a　　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のほかにも、Kaggleなどのデータサイエンスのコンテストなどがありますので、スキルを上げていきたい方はチャレンジしてみてください。課題を提出するまでにいたらなくとも、Discussionなどで色々な人が自分たちの手法やアプローチを紹介したりしていますので、データ分析を学ぶ上でとても参考になります。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
